{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_ModelosRegresion.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPdFpHqf/6w9XLJhGOHtVp6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"CLZl1pYh6OBf","colab_type":"text"},"source":["# Modelos de regresión con datos numéricos, imágenes y mixto"]},{"cell_type":"markdown","metadata":{"id":"ByuLSB7NZ1og","colab_type":"text"},"source":["Montamos la unidad de GDrive"]},{"cell_type":"code","metadata":{"id":"Lz48Aja46X6e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1593361957922,"user_tz":-120,"elapsed":17698,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"dab02c72-3f07-4461-aafc-d9667ec549ae"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1SsAhYkO6bY4","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593362218993,"user_tz":-120,"elapsed":12254,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Copiamos los ficheros de GDrive al entorno de ejecución\n","!cp /content/drive/My\\ Drive/x_train_num.npy x_train_num.npy\n","!cp /content/drive/My\\ Drive/x_train_img.npy x_train_img.npy\n","!cp /content/drive/My\\ Drive/x_val_num.npy x_val_num.npy\n","!cp /content/drive/My\\ Drive/x_val_img.npy x_val_img.npy\n","!cp /content/drive/My\\ Drive/x_test_num.npy x_test_num.npy\n","!cp /content/drive/My\\ Drive/x_test_img.npy x_test_img.npy\n","!cp /content/drive/My\\ Drive/y_train_reg.npy y_train_reg.npy\n","!cp /content/drive/My\\ Drive/y_val_reg.npy y_val_reg.npy\n","!cp /content/drive/My\\ Drive/y_test_reg.npy y_test_reg.npy"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"zwAq5Y-x6q2h","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593362221102,"user_tz":-120,"elapsed":807,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Cargamos los ficheros a variables de nuestro entorno\n","import numpy as np\n","x_train_num = np.load('x_train_num.npy')\n","x_train_img = np.load('x_train_img.npy')\n","x_val_num = np.load('x_val_num.npy')\n","x_val_img = np.load('x_val_img.npy')\n","x_test_num = np.load('x_test_num.npy')\n","x_test_img = np.load('x_test_img.npy')\n","y_train_reg = np.load('y_train_reg.npy')\n","y_val_reg = np.load('y_val_reg.npy')\n","y_test_reg = np.load('y_test_reg.npy')"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"KsKQPmSu8qRN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1593362222344,"user_tz":-120,"elapsed":407,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"b716c6f1-1183-49df-b1af-4b20eb83b3f0"},"source":["# Mostramos la forma de los arrays para ver que no haya errores\n","print(\"datos numericos de train:\", x_train_num.shape)\n","print(\"datos de imágenes de train:\",x_train_img.shape)\n","print(\"valores de train:\",y_train_reg.shape)\n","print(\"datos numericos de validación:\",x_val_num.shape)\n","print(\"datos de imágenes de validación:\",x_val_img.shape)\n","print(\"valores de validación:\",y_val_reg.shape)\n","print(\"datos numericos de test:\",x_test_num.shape)\n","print(\"datos de imágenes de test:\",x_test_img.shape)\n","print(\"valores de test:\",y_test_reg.shape)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["datos numericos de train: (7125, 30)\n","datos de imágenes de train: (7125, 64, 64, 3)\n","valores de train: (7125,)\n","datos numericos de validación: (814, 30)\n","datos de imágenes de validación: (814, 64, 64, 3)\n","valores de validación: (814,)\n","datos numericos de test: (2687, 30)\n","datos de imágenes de test: (2687, 64, 64, 3)\n","valores de test: (2687,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5Dkrd_cQiOlg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593362228253,"user_tz":-120,"elapsed":476,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Hacemos una transformación logarítmica a los precios\n","y_train_reg = np.log10(y_train_reg)\n","y_val_reg = np.log10(y_val_reg)\n","y_test_reg = np.log10(y_test_reg)"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"49UoCf4E99XC","colab_type":"text"},"source":["### Modelo de regresión sólo con datos numéricos"]},{"cell_type":"markdown","metadata":{"id":"lN5cJV0s-Zes","colab_type":"text"},"source":["Creamos un modelo secuencial con una primera capa densa con 8 neuronas. En esa primera capa hay que pasar la dimensión y la función de activación es relu. La siguiente capa que añadimos ya es más pequeña con 4 neuronas y también función de activación relu. La última capa al ser una red para regresión tiene sólo una neurona y función de activación linear. Es exactamente igual al de clasificación pero cambiando esta última capa."]},{"cell_type":"code","metadata":{"id":"EQyIH5mc9DMd","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593362231686,"user_tz":-120,"elapsed":430,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","model = Sequential()\n","model.add(Dense(8, input_dim=x_train_num.shape[1], activation=\"relu\"))\n","model.add(Dense(4, activation=\"relu\"))\n","model.add(Dense(1, activation=\"linear\"))"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MwCEknd0_Nyq","colab_type":"text"},"source":["Vamos a usar el optimizador Adam y la función de pérdidas el error cuadrático medio."]},{"cell_type":"code","metadata":{"id":"XtgVmcX1_OLO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593362365369,"user_tz":-120,"elapsed":131020,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"5a15b001-c118-4c73-b41f-03fa30bdffe4"},"source":["opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","model.compile(loss=\"mean_squared_error\", optimizer=opt)\n","# train the model\n","print(\"[INFO] training model...\")\n","model.fit(x=x_train_num, y=y_train_reg, \n","\tvalidation_data=(x_val_num, y_val_reg),\n","\tepochs=50, batch_size=8)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Epoch 1/50\n","891/891 [==============================] - 3s 3ms/step - loss: 34.5914 - val_loss: 0.5594\n","Epoch 2/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.5371 - val_loss: 0.2552\n","Epoch 3/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.1635 - val_loss: 0.1211\n","Epoch 4/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0888 - val_loss: 0.0898\n","Epoch 5/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0767 - val_loss: 0.0871\n","Epoch 6/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 7/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 8/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 9/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 10/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 11/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 12/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 13/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 14/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0761 - val_loss: 0.0869\n","Epoch 15/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0871\n","Epoch 16/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 17/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 18/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 19/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 20/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 21/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 22/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0871\n","Epoch 23/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 24/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0872\n","Epoch 25/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 26/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 27/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0761 - val_loss: 0.0869\n","Epoch 28/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 29/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 30/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 31/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0761 - val_loss: 0.0870\n","Epoch 32/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 33/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 34/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 35/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 36/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0871\n","Epoch 37/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 38/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0761 - val_loss: 0.0869\n","Epoch 39/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 40/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 41/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 42/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 43/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 44/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 45/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n","Epoch 46/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 47/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 48/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0869\n","Epoch 49/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0871\n","Epoch 50/50\n","891/891 [==============================] - 3s 3ms/step - loss: 0.0760 - val_loss: 0.0870\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8b30eff860>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"markdown","metadata":{"id":"wiCmkquZB0Wc","colab_type":"text"},"source":["Comprobamos el modelo con los datos de test."]},{"cell_type":"code","metadata":{"id":"kRukGa7P_jp1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593362365642,"user_tz":-120,"elapsed":83182,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"e6d53914-89e4-4962-bd53-407d1d857d43"},"source":["scores = model.evaluate(x_test_num, y_test_reg, verbose=0)\n","print('Loss: %.3f' % scores)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Loss: 0.078\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5qwGtwRMzJrY","colab_type":"text"},"source":["Vemos como en la época 6 habíamos llegago a un mínimo en la función de pérdidas y ya no se producen mejoras."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"X0P3nETDCDIN"},"source":["### Modelo de regresión sólo con imágenes"]},{"cell_type":"markdown","metadata":{"id":"c8NzgGoCAPBS","colab_type":"text"},"source":["En esta ocación usaremos una red neuronal convolucional para poder trabajar con las imágenes. Crearemos el modelo mediante un método funcional en vez de secuencial como anteriormente. Dependiendo de los filtros que pasemos creará diferentes capas, en este caso crearemos una de 16, otra de 32 y otra de 64. En la primera iteración indicamos la dimensión de los datos al igual que hacíamos en el modelo secuencial. Es igual que el modelo de clasificación pero cambiando la última capa."]},{"cell_type":"code","metadata":{"id":"OPq71P7BCVXB","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593362447318,"user_tz":-120,"elapsed":645,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input\n","# Tamaño de las imágenes\n","inputShape = (64, 64, 3)\n","chanDim = -1\n","# Filtros que vamos a aplicar en las capas convolucionales\n","filters=(16, 32, 64)\n","inputs = Input(shape=inputShape)\n","# Recorremos el bucle creando las diferentes capas\n","for (i, f) in enumerate(filters):\n","\t\t# si es la primera capa indicamos el inputshape\n","  if i == 0:\n","\t  x = inputs\n","\t# CONV => BN => RELU => POOL\n","  x = Conv2D(f, (3, 3), padding=\"same\")(x)\n","  x = BatchNormalization(axis=chanDim)(x)\n","  x = Activation(\"relu\")(x)\n","  x = MaxPooling2D(pool_size=(2, 2))(x)\n","\t\n","# Aplanamos los datos y ponemos una capa densa de 16 neuronas con activación relu\n","x = Flatten()(x)\n","x = Dense(16)(x)\n","x = BatchNormalization(axis=chanDim)(x)\n","x = Activation(\"relu\")(x)\n","x = Dropout(0.5)(x)\n","# Añadimos otra capa densa de 4 neuronas y activación relu\n","x = Dense(4)(x)\n","x = Activation(\"relu\")(x)\n","# Añadimos la última capa con 1 neuronas y función linear para la regresión \n","x = Dense(1, activation=\"linear\")(x)\n","# Construimos la red neuronal\n","model = Model(inputs, x)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"COeYkZ9zJXIW"},"source":["Vamos a usar el optimizador Adam y la función de pérdidas el error cuadrático medio."]},{"cell_type":"code","metadata":{"id":"zUZ1RIjaIxOy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593362772687,"user_tz":-120,"elapsed":318491,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"ffa36c23-0bca-44de-ffcd-bb23da35e5d5"},"source":["opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","model.compile(loss=\"mean_squared_error\", optimizer=opt)\n","# entrenamos el modelo\n","print(\"[INFO] training model...\")\n","model.fit(x=x_train_img, y=y_train_reg, \n","    validation_data=(x_val_img, y_val_reg),\n","    epochs=50, batch_size=8)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Epoch 1/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.4865 - val_loss: 0.0835\n","Epoch 2/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.1042 - val_loss: 0.0818\n","Epoch 3/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0816 - val_loss: 0.0804\n","Epoch 4/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0760 - val_loss: 0.0793\n","Epoch 5/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0732 - val_loss: 0.0780\n","Epoch 6/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0710 - val_loss: 0.0766\n","Epoch 7/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0702 - val_loss: 0.0826\n","Epoch 8/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0689 - val_loss: 0.0749\n","Epoch 9/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0668 - val_loss: 0.0763\n","Epoch 10/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0653 - val_loss: 0.0814\n","Epoch 11/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0647 - val_loss: 0.0793\n","Epoch 12/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0644 - val_loss: 0.0720\n","Epoch 13/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0637 - val_loss: 0.0753\n","Epoch 14/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0628 - val_loss: 0.0726\n","Epoch 15/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0621 - val_loss: 0.0708\n","Epoch 16/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0610 - val_loss: 0.0804\n","Epoch 17/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0592 - val_loss: 0.0749\n","Epoch 18/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0578 - val_loss: 0.0683\n","Epoch 19/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0567 - val_loss: 0.0696\n","Epoch 20/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0544 - val_loss: 0.0803\n","Epoch 21/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0527 - val_loss: 0.0777\n","Epoch 22/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0522 - val_loss: 0.0762\n","Epoch 23/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0489 - val_loss: 0.0759\n","Epoch 24/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0489 - val_loss: 0.0713\n","Epoch 25/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0470 - val_loss: 0.0712\n","Epoch 26/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0448 - val_loss: 0.0777\n","Epoch 27/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0434 - val_loss: 0.0754\n","Epoch 28/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0435 - val_loss: 0.0724\n","Epoch 29/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0422 - val_loss: 0.0778\n","Epoch 30/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0410 - val_loss: 0.0759\n","Epoch 31/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0390 - val_loss: 0.0729\n","Epoch 32/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0383 - val_loss: 0.0807\n","Epoch 33/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0373 - val_loss: 0.0794\n","Epoch 34/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0361 - val_loss: 0.0743\n","Epoch 35/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0350 - val_loss: 0.0825\n","Epoch 36/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0348 - val_loss: 0.0766\n","Epoch 37/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0340 - val_loss: 0.0785\n","Epoch 38/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0344 - val_loss: 0.0803\n","Epoch 39/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0329 - val_loss: 0.0787\n","Epoch 40/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0324 - val_loss: 0.0769\n","Epoch 41/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0310 - val_loss: 0.0802\n","Epoch 42/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0315 - val_loss: 0.0853\n","Epoch 43/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0305 - val_loss: 0.0811\n","Epoch 44/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0301 - val_loss: 0.0819\n","Epoch 45/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0291 - val_loss: 0.0853\n","Epoch 46/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0290 - val_loss: 0.0825\n","Epoch 47/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0287 - val_loss: 0.0831\n","Epoch 48/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0290 - val_loss: 0.0858\n","Epoch 49/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0279 - val_loss: 0.0857\n","Epoch 50/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0275 - val_loss: 0.0857\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8b2bbb37f0>"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d2VihmpFSV_k"},"source":["Comprobamos el modelo con los datos de test."]},{"cell_type":"code","metadata":{"id":"TCbpVU9uJxY-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593363327177,"user_tz":-120,"elapsed":1175,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"6006f7c3-8319-4a73-eed5-c4d2e395f38f"},"source":["scores = model.evaluate(x_test_img, y_test_reg, verbose=0)\n","print('Loss: %.3f' % scores)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Loss: 0.076\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TYQ-zeL2mGdy","colab_type":"text"},"source":["En esta ocasión vemos como el modelo tiene overfitting, se ha aprendido los datos de entrenamiento y se ajusta muy bien a estos, pero no a los de test o validación. Podemos comprobarlo por la diferencia entre cada una de las funciones de pérdidas."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7ziE6moFSsjv"},"source":["### Modelo de regresión sólo con datos mixtos, imágenes y numéricos."]},{"cell_type":"markdown","metadata":{"id":"Era1QWpgSzth","colab_type":"text"},"source":["En esta ocasión usaremos los dos tipos de datos que hemos visto anteriormente. Vamos a crear un modelo con dos ramas:\n","\n","\n","1.   Rama 1: una red neuronal para analizar los datos numéricos, exactamente igual a la que hemos usado antes, pero sin la capa final de regresión.\n","2.   Rama 2: una red neuronal convolucional para trabajar con las imágenes, exactamente igual a la anterior, pero sin la capa final de regresión.\n","\n","Posteriormente combinaremos ambas ramas creando otra capa densa de 4 neuronas con función de activación relu y la capa final de regresión con 1 neurona y función de activación linear.\n"]},{"cell_type":"code","metadata":{"id":"JJl-4ltySeNO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363361775,"user_tz":-120,"elapsed":494,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Creamos la rama numérica\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.optimizers import Adam\n","\n","mlp = Sequential()\n","mlp.add(Dense(8, input_dim=x_train_num.shape[1], activation=\"relu\"))\n","mlp.add(Dense(4, activation=\"relu\"))"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"eBqVJtwcUfpH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363363136,"user_tz":-120,"elapsed":668,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Creamos la rama que trabaja con imágenes\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Dropout, Dense, Flatten, Input\n","# Tamaño de las imágenes\n","inputShape = (64, 64, 3)\n","chanDim = -1\n","# Filtros que vamos a aplicar en las capas convolucionales\n","filters=(16, 32, 64)\n","inputs = Input(shape=inputShape)\n","# Recorremos el bucle creando las diferentes capas\n","for (i, f) in enumerate(filters):\n","\t\t# si es la primera capa indicamos el inputshape\n","  if i == 0:\n","\t  x = inputs\n","\t# CONV => BN => RELU => POOL\n","  x = Conv2D(f, (3, 3), padding=\"same\")(x)\n","  x = BatchNormalization(axis=chanDim)(x)\n","  x = Activation(\"relu\")(x)\n","  x = MaxPooling2D(pool_size=(2, 2))(x)\n","\t\n","# Aplanamos los datos y ponemos una capa densa de 16 neuronas con activación relu\n","x = Flatten()(x)\n","x = Dense(16)(x)\n","x = BatchNormalization(axis=chanDim)(x)\n","x = Activation(\"relu\")(x)\n","x = Dropout(0.5)(x)\n","# Añadimos otra capa densa de 4 neuronas y activación relu\n","x = Dense(4)(x)\n","x = Activation(\"relu\")(x)\n","# Construimos la red neuronal\n","cnn = Model(inputs, x)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ZZro3knUxii","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363365646,"user_tz":-120,"elapsed":510,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["from tensorflow.keras.layers import concatenate\n","# Combinamos ambas redes\n","combinedInput = concatenate([mlp.output, cnn.output])"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"fSZh_-GbVA9m","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363366960,"user_tz":-120,"elapsed":590,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Añadimos la capa densa con 4 neuronas y la de 3 para la clasificación\n","x = Dense(4, activation=\"relu\")(combinedInput)\n","x = Dense(1, activation=\"linear\")(x)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_eQbdj-VSow","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363368626,"user_tz":-120,"elapsed":589,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Construimos el modelo que combina datos numéricos e imágenes\n","model = Model(inputs=[mlp.input, cnn.input], outputs=x)"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"id":"dt0VfP0sVjHn","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593363370163,"user_tz":-120,"elapsed":678,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}}},"source":["# Usamos de nuevo el optimizados Adam y la función de pérdidas error cuadrático medio y compilamos el modelo\n","opt = Adam(lr=1e-3, decay=1e-3 / 200)\n","model.compile(loss=\"mean_squared_error\", optimizer=opt)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymZA_lacV6It","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593363718995,"user_tz":-120,"elapsed":337631,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"e5171bfb-1a14-4104-cb58-1ce01c97e632"},"source":["# Entrenamos el modelo\n","print(\"[INFO] training model...\")\n","model.fit(\n","\tx=[x_train_num, x_train_img], y=y_train_reg,\n","\tvalidation_data=([x_val_num, x_val_img], y_val_reg),\n","\tepochs=50, batch_size=8)\n"],"execution_count":29,"outputs":[{"output_type":"stream","text":["[INFO] training model...\n","Epoch 1/50\n","891/891 [==============================] - 7s 8ms/step - loss: 84.1229 - val_loss: 0.1462\n","Epoch 2/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.1200 - val_loss: 0.0940\n","Epoch 3/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0821 - val_loss: 0.1287\n","Epoch 4/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0767 - val_loss: 0.0881\n","Epoch 5/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0727 - val_loss: 0.0909\n","Epoch 6/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0684 - val_loss: 0.0846\n","Epoch 7/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0672 - val_loss: 0.0648\n","Epoch 8/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0623 - val_loss: 0.0611\n","Epoch 9/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0571 - val_loss: 0.0573\n","Epoch 10/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0538 - val_loss: 0.0544\n","Epoch 11/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0470 - val_loss: 0.0601\n","Epoch 12/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0429 - val_loss: 0.0435\n","Epoch 13/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0403 - val_loss: 0.0379\n","Epoch 14/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0368 - val_loss: 0.0366\n","Epoch 15/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0337 - val_loss: 0.0343\n","Epoch 16/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0324 - val_loss: 0.0374\n","Epoch 17/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0324 - val_loss: 0.0328\n","Epoch 18/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0312 - val_loss: 0.0335\n","Epoch 19/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0302 - val_loss: 0.0337\n","Epoch 20/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0292 - val_loss: 0.0298\n","Epoch 21/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0282 - val_loss: 0.0311\n","Epoch 22/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0277 - val_loss: 0.0605\n","Epoch 23/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0276 - val_loss: 0.0277\n","Epoch 24/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0258 - val_loss: 0.0281\n","Epoch 25/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0257 - val_loss: 0.0412\n","Epoch 26/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0261 - val_loss: 0.0331\n","Epoch 27/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0265 - val_loss: 0.0286\n","Epoch 28/50\n","891/891 [==============================] - 6s 7ms/step - loss: 0.0238 - val_loss: 0.0264\n","Epoch 29/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0232 - val_loss: 0.0371\n","Epoch 30/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0225 - val_loss: 0.0296\n","Epoch 31/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0218 - val_loss: 0.0289\n","Epoch 32/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0215 - val_loss: 0.0297\n","Epoch 33/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0215 - val_loss: 0.0270\n","Epoch 34/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0202 - val_loss: 0.0374\n","Epoch 35/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0194 - val_loss: 0.0340\n","Epoch 36/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0191 - val_loss: 0.0375\n","Epoch 37/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0191 - val_loss: 0.0291\n","Epoch 38/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0580 - val_loss: 0.0799\n","Epoch 39/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0661 - val_loss: 0.0743\n","Epoch 40/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0638 - val_loss: 0.0701\n","Epoch 41/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0609 - val_loss: 0.0724\n","Epoch 42/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0595 - val_loss: 0.0705\n","Epoch 43/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0580 - val_loss: 0.0702\n","Epoch 44/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0558 - val_loss: 0.0711\n","Epoch 45/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0551 - val_loss: 0.0720\n","Epoch 46/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0524 - val_loss: 0.0935\n","Epoch 47/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0515 - val_loss: 0.0725\n","Epoch 48/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0492 - val_loss: 0.0806\n","Epoch 49/50\n","891/891 [==============================] - 7s 7ms/step - loss: 0.0477 - val_loss: 0.0722\n","Epoch 50/50\n","891/891 [==============================] - 7s 8ms/step - loss: 0.0466 - val_loss: 0.0762\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7f8b3399b1d0>"]},"metadata":{"tags":[]},"execution_count":29}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"plzMH0WvYYik"},"source":["Comprobamos el modelo con los datos de test."]},{"cell_type":"code","metadata":{"id":"IoGTEIiCW3wB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593363725030,"user_tz":-120,"elapsed":1017,"user":{"displayName":"Alejandro Lopez Sanchez","photoUrl":"","userId":"15630027770360093716"}},"outputId":"95294367-a718-479b-e102-c91a352c6a0d"},"source":["scores = model.evaluate([x_test_num, x_test_img], y_test_reg, verbose=0)\n","print('Loss: %.3f' % scores)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Loss: 0.071\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zc26qev2ojvO","colab_type":"text"},"source":["Creo que ha ocurrido lo mismo que antes y tenemos overfitting, ya que se puede obervar como la función de pérdidas va reduciendo en train época a época, sin embargo en validación permanece casi constante."]}]}